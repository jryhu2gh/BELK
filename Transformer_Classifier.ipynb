{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e2f0c3c-996b-4eb9-9766-dba657e00df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.metrics import average_precision_score as APS\n",
    "\n",
    "file_path = './leash-BELKA/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7b029e4-ce0c-47ea-9a6f-d6886acbb4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the entire data frame\n",
    "df = pd.read_parquet(file_path+'train_enc.parquet', engine='pyarrow', columns=None, filters=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039b3189-d073-4eaf-9823-c093682de962",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8183a826-7e65-4d38-8531-f3aa3c0525ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# Function to filter, sample, and combine data\n",
    "def RandomSample(data, labels, ratio_of_one):\n",
    "    # Separate data into two groups based on labels\n",
    "    data_class_0 = data[labels.squeeze() == 0]\n",
    "    data_class_1 = data[labels.squeeze() == 1]\n",
    "    \n",
    "    # Determine the number of samples for each group\n",
    "    num_class_0 = data_class_0.size(0)\n",
    "    num_class_1 = data_class_1.size(0)\n",
    "    \n",
    "    # Calculate the number of samples needed for class 1 based on the ratio\n",
    "    desired_num_class_0 = int(num_class_1 * (1-ratio_of_one) / ratio_of_one)\n",
    "    print(num_class_1, desired_num_class_0)\n",
    "    \n",
    "    # If desired number of class 1 samples is more than available, use all\n",
    "    desired_num_class_0 = min(desired_num_class_0, num_class_0)\n",
    "    \n",
    "    # Randomly sample from each group\n",
    "    sampled_class_0_indices = torch.randperm(num_class_0)\n",
    "    # sampled_class_1_indices = torch.randperm(num_class_1)\n",
    "    \n",
    "    sampled_class_0 = data_class_0[sampled_class_0_indices[:desired_num_class_0]]\n",
    "    # sampled_class_1 = data_class_1[sampled_class_1_indices[:desired_num_class_1]]\n",
    "    \n",
    "    # Combine the samples\n",
    "    combined_data = torch.cat([sampled_class_0, data_class_1], dim=0)\n",
    "    combined_labels = torch.cat([torch.zeros(desired_num_class_0), torch.ones(num_class_1)], dim=0)\n",
    "    \n",
    "    # Shuffle the combined data\n",
    "    perm = torch.randperm(combined_data.size(0))\n",
    "    combined_data = combined_data[perm]\n",
    "    combined_labels = combined_labels[perm]\n",
    "    \n",
    "    return combined_data, combined_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816d0426-1031-4786-8fd2-1102313dbb46",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ff285cc-75de-4805-b9c4-d40a588e6da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ee2c9f1-1d35-4d3a-bbab-f93faf32d514",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        # Ensure that the model dimension (d_model) is divisible by the number of heads\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        # Initialize dimensions\n",
    "        self.d_model = d_model # Model's dimension\n",
    "        self.num_heads = num_heads # Number of attention heads\n",
    "        self.d_k = d_model // num_heads # Dimension of each head's key, query, and value\n",
    "        \n",
    "        # Linear layers for transforming inputs\n",
    "        self.W_q = nn.Linear(d_model, d_model) # Query transformation\n",
    "        self.W_k = nn.Linear(d_model, d_model) # Key transformation\n",
    "        self.W_v = nn.Linear(d_model, d_model) # Value transformation\n",
    "        self.W_o = nn.Linear(d_model, d_model) # Output transformation\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        # Calculate attention scores\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        \n",
    "        # Apply mask if provided (useful for preventing attention to certain parts like padding)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        # Softmax is applied to obtain attention probabilities\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        \n",
    "        # Multiply by values to obtain the final output\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output\n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        # Reshape the input to have num_heads for multi-head attention\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "    def combine_heads(self, x):\n",
    "        # Combine the multiple heads back to original shape\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "        \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        # Apply linear transformations and split heads\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "        \n",
    "        # Perform scaled dot-product attention\n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        \n",
    "        # Combine heads and apply output transformation\n",
    "        output = self.W_o(self.combine_heads(attn_output))\n",
    "        return output\n",
    "\n",
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e2abe7d-8e40-494c-9310-4481368ec548",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout): # input size: (B, S, C)\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask = None):\n",
    "        attn_output = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x # output size (B, S ,C)\n",
    "\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, input_dim = 142, num_class = 2, d_model = 512, d_ff = 128, verbo_size = 36, num_heads = 8, dropout = 0.1):\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "        self.embed = nn.Embedding(verbo_size, d_model)\n",
    "        self.encode = EncoderLayer(d_model, num_heads, d_ff, dropout)\n",
    "        self.fc = nn.Linear(input_dim, num_class)\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, x): # input dimension (B, S)\n",
    "        x = self.embed(x)\n",
    "        x1 = self.encode(x)\n",
    "        x2, _ = torch.max(x1, dim = -1, keepdim = False)\n",
    "        output = self.fc(x2)\n",
    "        output = self.softmax(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6e64a1-e1c1-4dc7-8e9e-1b9f5cf04de3",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504f4d55-05f7-4cd5-9fae-395eb4bab328",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3a42c945-8401-463b-968b-4c48165fc8d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "TransformerClassifier                    [2, 2]                    --\n",
       "├─Embedding: 1-1                         [2, 142, 512]             18,944\n",
       "├─EncoderLayer: 1-2                      [2, 142, 512]             --\n",
       "│    └─MultiHeadAttention: 2-1           [2, 142, 512]             --\n",
       "│    │    └─Linear: 3-1                  [2, 142, 512]             262,656\n",
       "│    │    └─Linear: 3-2                  [2, 142, 512]             262,656\n",
       "│    │    └─Linear: 3-3                  [2, 142, 512]             262,656\n",
       "│    │    └─Linear: 3-4                  [2, 142, 512]             262,656\n",
       "│    └─Dropout: 2-2                      [2, 142, 512]             --\n",
       "│    └─LayerNorm: 2-3                    [2, 142, 512]             1,024\n",
       "│    └─PositionWiseFeedForward: 2-4      [2, 142, 512]             --\n",
       "│    │    └─Linear: 3-5                  [2, 142, 128]             65,664\n",
       "│    │    └─ReLU: 3-6                    [2, 142, 128]             --\n",
       "│    │    └─Linear: 3-7                  [2, 142, 512]             66,048\n",
       "│    └─Dropout: 2-5                      [2, 142, 512]             --\n",
       "│    └─LayerNorm: 2-6                    [2, 142, 512]             1,024\n",
       "├─Linear: 1-3                            [2, 2]                    286\n",
       "├─Softmax: 1-4                           [2, 2]                    --\n",
       "==========================================================================================\n",
       "Total params: 1,203,614\n",
       "Trainable params: 1,203,614\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 2.41\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 9.60\n",
       "Params size (MB): 4.81\n",
       "Estimated Total Size (MB): 14.41\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "from tqdm.notebook import tqdm\n",
    "torch.cuda.empty_cache()\n",
    "device = 'cuda'\n",
    "model = TransformerClassifier(input_dim = 142, num_class = 2, d_model = 512, d_ff = 128, verbo_size = 37, num_heads = 8, dropout = 0.1)\n",
    "model.to(device)\n",
    "summary(model, input_size=(2, 142), dtypes=[torch.long])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bbe37c6f-5d98-4aa6-a6e9-10af4e5b6bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.207805\n"
     ]
    }
   ],
   "source": [
    "page_size = int(2e6)\n",
    "i = 0\n",
    "num_pages = int(df.shape[0]//page_size)\n",
    "print(df.shape[0]/page_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "83dfc4df-3be2-461f-b043-84b6ef9bf788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "10501 1039599\n",
      "torch.Size([1050100, 2])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "106726d8b50641199dd70aa0d48191ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2051 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000, Loss: 0.0274\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99603a7b6e91474c968766ffe77370d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2051 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10000, Loss: 0.0274\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffef9127c69d471c9fb07b3e7f99637a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2051 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10000, Loss: 0.0274\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "766ee00db49d4757895cd79641c64055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2051 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10000, Loss: 0.0274\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "092d0bc751f243dbb64468add717ba25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2051 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10000, Loss: 0.0274\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a206185a48234e529e56825d1a1d9c89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2051 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10000, Loss: 0.0274\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b7b50fe58f34f979784c0ed52a26790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2051 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10000, Loss: 0.0274\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c47d51017443451982a95d5b4c21923d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2051 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[94], line 53\u001b[0m\n\u001b[0;32m     51\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     52\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mint32))\n\u001b[1;32m---> 53\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     56\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1185\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1186\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1187\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\functional.py:3086\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3084\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3085\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3086\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\fx\\traceback.py:67\u001b[0m, in \u001b[0;36mformat_stack\u001b[1;34m()\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [current_meta\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack_trace\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;66;03m# fallback to traceback.format_stack()\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m traceback\u001b[38;5;241m.\u001b[39mformat_list(\u001b[43mtraceback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\traceback.py:231\u001b[0m, in \u001b[0;36mextract_stack\u001b[1;34m(f, limit)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    230\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[1;32m--> 231\u001b[0m stack \u001b[38;5;241m=\u001b[39m \u001b[43mStackSummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwalk_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m stack\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stack\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\traceback.py:393\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f, lineno \u001b[38;5;129;01min\u001b[39;00m frame_gen:\n\u001b[0;32m    391\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m f, (lineno, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mklass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_from_extended_frame_gen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextended_frame_gen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_lines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlookup_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapture_locals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapture_locals\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\traceback.py:432\u001b[0m, in \u001b[0;36mStackSummary._extract_from_extended_frame_gen\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    428\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(FrameSummary(\n\u001b[0;32m    429\u001b[0m         filename, lineno, name, lookup_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39mf_locals,\n\u001b[0;32m    430\u001b[0m         end_lineno\u001b[38;5;241m=\u001b[39mend_lineno, colno\u001b[38;5;241m=\u001b[39mcolno, end_colno\u001b[38;5;241m=\u001b[39mend_colno))\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m fnames:\n\u001b[1;32m--> 432\u001b[0m     \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckcache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;66;03m# If immediate lookup was desired, trigger lookups now.\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lookup_lines:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\linecache.py:72\u001b[0m, in \u001b[0;36mcheckcache\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m   \u001b[38;5;66;03m# no-op for files loaded via a __loader__\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 72\u001b[0m     stat \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstat(fullname)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     cache\u001b[38;5;241m.\u001b[39mpop(filename, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model.to(device)\n",
    "torch.cuda.empty_cache()\n",
    "weights = torch.tensor([0.05, 0.95]).to(device) # set loss weight\n",
    "criterion = nn.CrossEntropyLoss( weight = weights )\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "num_epochs = 10000\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "model.train()\n",
    "i = 0\n",
    "num_pages = int(df.shape[0]//page_size)\n",
    "batch_size = 512\n",
    "update_index = 999\n",
    "\n",
    "ratio_of_one = 0.01    # control how may percentage positive data occupies\n",
    "for epoch in range(num_epochs):    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Get a small portion of the entire data\n",
    "    if update_index>9: # Control how many epochs run for each page\n",
    "        update_index = 0\n",
    "        df_small = df.iloc[int(i*page_size):int((i+1)*page_size)]\n",
    "        i+=1\n",
    "        \n",
    "        # Once it reaches the end of data, restart from teh first page\n",
    "        if i>=num_pages-1:\n",
    "            i = 0\n",
    "\n",
    "        # Create dataloader. Use all positive data and randomly sample negative data to the desired ratio of one.\n",
    "        df_values = df_small.values\n",
    "        df_torch = torch.tensor(df_values,dtype = torch.float32)\n",
    "        \n",
    "        X_train = df_torch[:,:142]\n",
    "        y_train = df_torch[:,142:]\n",
    "        y_train = y_train.bool().any(dim=1,keepdim = True).to(torch.float32)\n",
    "\n",
    "        print(ratio_of_one)\n",
    "        X_train_combined, y_train_combined = RandomSample(X_train, y_train, ratio_of_one)\n",
    "        y_train_combined = nn.functional.one_hot(y_train_combined.to(torch.int64), num_classes=2)\n",
    "        y_train_combined = y_train_combined.to(torch.float32)\n",
    "        Combined_Dataset = CustomDataset(X_train_combined, y_train_combined)\n",
    "\n",
    "        Combined_DataLoader = DataLoader(Combined_Dataset, batch_size=batch_size, shuffle = True)\n",
    "    update_index += 1\n",
    "\n",
    "    # Training starts here.\n",
    "    for inputs, targets in tqdm(Combined_DataLoader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.to(torch.int32))\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(Combined_DataLoader.dataset)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "759a1dce-abbe-429d-ae69-f017b37b46a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10501 1166\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "771ef08b2e52429cb37d9f4482c5c978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1606, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#####\n",
    "# Validate model performance by using the last page of data. (Never seen by the model)\n",
    "length = df.shape[0]\n",
    "val_df = df.iloc[length-page_size:]\n",
    "val_values = val_df.values\n",
    "val_torch = torch.tensor(val_values,dtype = torch.float32)\n",
    "\n",
    "X_val = val_torch[:,:142]\n",
    "y_val = val_torch[:,142:]\n",
    "y_val = y_val.bool().any(dim=1,keepdim = True).to(torch.float32)\n",
    "\n",
    "X_val_combined, y_val_combined = RandomSample(X_val, y_val, 0.9)\n",
    "\n",
    "y_val_combined = nn.functional.one_hot(y_val_combined.to(torch.int64), num_classes=2)\n",
    "y_val_combined = y_val_combined.to(torch.float32)\n",
    "\n",
    "Combined_Dataset = CustomDataset(X_val_combined, y_val_combined)\n",
    "Combined_DataLoader = DataLoader(Combined_Dataset, batch_size=batch_size, shuffle = True)\n",
    "\n",
    "model.eval()\n",
    "accuracy = 0\n",
    "count = 0\n",
    "for inputs, targets in tqdm(Combined_DataLoader):\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    outputs = model(inputs.to(torch.int32))\n",
    "\n",
    "    predict_class = torch.argmax(outputs,dim=1)\n",
    "    true_class = torch.argmax(targets,dim=1)\n",
    "    true_count = (predict_class==true_class).to(torch.float32).sum()    \n",
    "    res = true_count / batch_size\n",
    "    # print(res)\n",
    "    accuracy+=res\n",
    "    count+=1\n",
    "    \n",
    "print(f'Accuracy: {accuracy/count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcede940-094c-4a6c-904b-93e4511a89eb",
   "metadata": {},
   "source": [
    "## Generate submission data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c88ddc5-a0ff-4cd4-8b58-ece6f01f1f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1674896, 142)\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_parquet(file_path+'test_enc.parquet', engine='pyarrow', columns=None, filters=None)\n",
    "print(df_test.shape)\n",
    "df_values = df_test.values\n",
    "df_test_tensor = torch.tensor(df_values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5218f4a4-5f10-44b5-9765-19c6a6a77bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv = pd.read_csv(file_path+'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466cde82-ced7-48c5-98b9-e2064ff2439f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "model = torch.load('model_v1.pth')\n",
    "test_csv['binds']=0\n",
    "print(test_csv.head(3))\n",
    "model.eval()\n",
    "result = []\n",
    "batch_size = 4096\n",
    "for i in range(int(df_test_tensor.shape[0]//batch_size)):\n",
    "    inputs = df_test_tensor[int(i*batch_size):int((i+1)*batch_size)].view(batch_size,142)\n",
    "    pred = model(inputs.to(device))\n",
    "    pred = pred.detach().cpu().numpy()\n",
    "    pred_score = pred[:,1]# np.argmax(pred, axis=1)\n",
    "    test_csv.loc[int(i*batch_size):int((i+1)*batch_size)-1,'binds'] = pred_score.flatten()\n",
    "\n",
    "columns_to_save = ['id', 'binds']  # Replace 'column1' with the actual column name you want to save\n",
    "\n",
    "# Save the selected columns to a new CSV file\n",
    "test_csv[columns_to_save].to_csv('sibmission.csv', index=False)\n",
    "\n",
    "print(\"New CSV file saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
